{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of writing_a_training_loop_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dupeljan/collab/blob/main/Copy_of_writing_a_training_loop_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf323e33b84"
      },
      "source": [
        "# Try to freeze weights in runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGU2ipaJpC8t"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae2407ad926f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W10xYtOImrI6"
      },
      "source": [
        "Setup dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suevcQFEmo1g"
      },
      "source": [
        "# Prepare the training dataset.\r\n",
        "batch_size = 64\r\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n",
        "x_train = np.reshape(x_train, (-1, 784))\r\n",
        "x_test = np.reshape(x_test, (-1, 784))\r\n",
        "\r\n",
        "# Reserve 10,000 samples for validation.\r\n",
        "x_val = x_train[-10000:]\r\n",
        "y_val = y_train[-10000:]\r\n",
        "x_train = x_train[:-10000]\r\n",
        "y_train = y_train[:-10000]\r\n",
        "\r\n",
        "# Prepare the training dataset.\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\r\n",
        "\r\n",
        "# Prepare the validation dataset.\r\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\r\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk9d-GNcosMi"
      },
      "source": [
        "# Eager mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaa775ce7dab"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
        "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2c6257b8d02"
      },
      "source": [
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6374be9e3d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d944be3d-49d5-48db-baeb-589b0a9de50f"
      },
      "source": [
        "def train(model, epochs = 2):\n",
        "  for epoch in range(epochs):\n",
        "      print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "      # Iterate over the batches of the dataset.\n",
        "      for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "          # Open a GradientTape to record the operations run\n",
        "          # during the forward pass, which enables auto-differentiation.\n",
        "          with tf.GradientTape() as tape:\n",
        "\n",
        "              # Run the forward pass of the layer.\n",
        "              # The operations that the layer applies\n",
        "              # to its inputs are going to be recorded\n",
        "              # on the GradientTape.\n",
        "              logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
        "\n",
        "              # Compute the loss value for this minibatch.\n",
        "              loss_value = loss_fn(y_batch_train, logits)\n",
        "\n",
        "          # Use the gradient tape to automatically retrieve\n",
        "          # the gradients of the trainable variables with respect to the loss.\n",
        "          grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "          # Run one step of gradient descent by updating\n",
        "          # the value of the variables to minimize the loss.\n",
        "          optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "          # Log every 200 batches.\n",
        "          if step % 200 == 0:\n",
        "              print(\n",
        "                  \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                  % (step, float(loss_value))\n",
        "              )\n",
        "              print(\"Seen so far: %s samples\" % ((step + 1) * 64))\n",
        "train(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 84.5313\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 2.1334\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.7563\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.6857\n",
            "Seen so far: 38464 samples\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.6501\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.5389\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.5519\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.5096\n",
            "Seen so far: 38464 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPf7R0cTnGcf"
      },
      "source": [
        "Check trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA74VQxKtLO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ef4eb7-f3f4-49e5-df7a-b868453dc892"
      },
      "source": [
        "[ x.name for x in model.trainable_weights]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dense_2/kernel:0',\n",
              " 'dense_2/bias:0',\n",
              " 'dense_3/kernel:0',\n",
              " 'dense_3/bias:0',\n",
              " 'predictions/kernel:0',\n",
              " 'predictions/bias:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukgwF6z90XqX"
      },
      "source": [
        "Freeze layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0W60mysyhYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f040df4-36ac-4652-dd0b-518baffdce14"
      },
      "source": [
        "def copy(weights):\r\n",
        "    res = []\r\n",
        "    for w in weights:\r\n",
        "      res.append(tf.identity(w))\r\n",
        "    return res \r\n",
        "\r\n",
        "\r\n",
        "weights = dict()\r\n",
        "# Freeze all layers besides the last one\r\n",
        "target_layer_name = 'predictions'\r\n",
        "for layer in model.layers:\r\n",
        "  if layer.weights:\r\n",
        "    if layer.name != target_layer_name:\r\n",
        "      layer.trainable = False\r\n",
        "    weights[layer.name] = copy(layer.weights)\r\n",
        "\r\n",
        "# Check trainable weights list\r\n",
        "[x.name for x in model.trainable_weights]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['predictions/kernel:0', 'predictions/bias:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFef2vRyyV5l"
      },
      "source": [
        "Train only last layer of model and check it\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYNWM3a10wlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c66247f-bd58-456a-a987-1199ff7498f0"
      },
      "source": [
        "train(model)\r\n",
        "\r\n",
        "def equal(w1, w2):\r\n",
        "    return [ bool(tf.math.reduce_all(tf.math.equal(w, w_saved))) \r\n",
        "              for w, w_saved in zip(w1, w2)]\r\n",
        "\r\n",
        "    \r\n",
        "for layer in model.layers:\r\n",
        "  if not layer.weights:\r\n",
        "    continue\r\n",
        "  if layer.name != target_layer_name:\r\n",
        "    assert all(equal(weights[layer.name], layer.weights))\r\n",
        "  else:\r\n",
        "    assert not all(equal(weights[layer.name], layer.weights))\r\n",
        "  print(\"{0} sqr diff: {1}\".format(\r\n",
        "        layer.name,\r\n",
        "        tf.math.reduce_sum(tf.math.pow(\r\n",
        "                        layer.weights[0] -  weights[layer.name][0], 2))\r\n",
        "    ))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.3266\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.3251\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.6280\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.2726\n",
            "Seen so far: 38464 samples\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.2719\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.7506\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.3221\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.4017\n",
            "Seen so far: 38464 samples\n",
            "dense_2 sqr diff: 0.0\n",
            "dense_3 sqr diff: 0.0\n",
            "predictions sqr diff: 0.02466883882880211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfNvxi79m113"
      },
      "source": [
        "Freezing in eager mode is working!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGuDJooK8-bU"
      },
      "source": [
        "You can freeze layer, but you can't set weight trainable attribute. If layer have trainable == false this it just not lised at `model.trainable_weights`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2k3dfDr4yg3",
        "outputId": "d2f0a492-fc75-4042-d958-2bc71f48408b"
      },
      "source": [
        "for layer in model.layers:\r\n",
        "  if layer.name != target_layer_name:\r\n",
        "    for weight in layer.weights:\r\n",
        "      print('w', weight.name, weight.trainable)\r\n",
        "    print('l', layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l digits False\n",
            "w dense/kernel:0 True\n",
            "w dense/bias:0 True\n",
            "l dense False\n",
            "w dense_1/kernel:0 True\n",
            "w dense_1/bias:0 True\n",
            "l dense_1 False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX49Y4BbfNwi"
      },
      "source": [
        "# Non eager mode with GradTape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdEMe8EWjR_c"
      },
      "source": [
        "Setup train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgLjY_Swfz_D"
      },
      "source": [
        "@tf.function\n",
        "def train():\n",
        "  epochs = 3\n",
        "  for epoch in range(epochs):\n",
        "      print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "      # Iterate over the batches of the dataset.\n",
        "      for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "          # Open a GradientTape to record the operations run\n",
        "          # during the forward pass, which enables auto-differentiation.\n",
        "          with tf.GradientTape() as tape:\n",
        "\n",
        "              # Run the forward pass of the layer.\n",
        "              # The operations that the layer applies\n",
        "              # to its inputs are going to be recorded\n",
        "              # on the GradientTape.\n",
        "              logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
        "\n",
        "              # Compute the loss value for this minibatch.\n",
        "              loss_value = loss_fn(y_batch_train, logits)\n",
        "\n",
        "          # Use the gradient tape to automatically retrieve\n",
        "          # the gradients of the trainable variables with respect to the loss.\n",
        "          grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "          # Run one step of gradient descent by updating\n",
        "          # the value of the variables to minimize the loss.\n",
        "          optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr8ol9rkjc8U"
      },
      "source": [
        "Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCyP2bGJfz-2"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
        "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOFz3u8pjJDN"
      },
      "source": [
        "Setup trainable params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eR7G8SRfz_E",
        "outputId": "01a3347e-5aab-4ca6-e595-f167cbc78245"
      },
      "source": [
        "def copy(weights):\r\n",
        "    res = []\r\n",
        "    for w in weights:\r\n",
        "      res.append(tf.identity(w))\r\n",
        "    return res \r\n",
        "\r\n",
        "\r\n",
        "weights = dict()\r\n",
        "def save_weight():\r\n",
        "  global weights\r\n",
        "  for layer in model.layers:\r\n",
        "    if layer.weights:\r\n",
        "      weights[layer.name] = copy(layer.weights)\r\n",
        "\r\n",
        "save_weight()\r\n",
        "\r\n",
        "# Freeze all layers besides the last one\r\n",
        "target_layer_name = 'predictions'\r\n",
        "for layer in model.layers:\r\n",
        "  if layer.weights:\r\n",
        "    if layer.name != target_layer_name:\r\n",
        "      layer.trainable = False\r\n",
        "\r\n",
        "# Check trainable weights list\r\n",
        "[x.name for x in model.trainable_weights]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['predictions/kernel:0', 'predictions/bias:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLJ0ZCdPnfyY"
      },
      "source": [
        "Try to train only last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmi_a3JYiexj",
        "outputId": "3c511c39-bf13-402f-994d-cb4bc4df288d"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "\n",
            "Start of epoch 1\n",
            "\n",
            "Start of epoch 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS5IrUxbnnqZ"
      },
      "source": [
        "Check freezing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_3EM4Xjfz_F",
        "outputId": "fe3a3df3-f422-4c67-a0a9-e645bebe2ed3"
      },
      "source": [
        "\r\n",
        "def equal(w1, w2):\r\n",
        "    return [ bool(tf.math.reduce_all(tf.math.equal(w, w_saved))) \r\n",
        "              for w, w_saved in zip(w1, w2)]\r\n",
        "\r\n",
        "def check_is_trainable():    \r\n",
        "  for layer in model.layers:\r\n",
        "    if not layer.weights:\r\n",
        "      continue\r\n",
        "    if layer.name != target_layer_name:\r\n",
        "      assert all(equal(weights[layer.name], layer.weights))\r\n",
        "    else:\r\n",
        "      assert not all(equal(weights[layer.name], layer.weights))\r\n",
        "    print(\"{0} sqr diff: {1}\".format(\r\n",
        "          layer.name,\r\n",
        "          tf.math.reduce_sum(tf.math.pow(\r\n",
        "                          layer.weights[0] -  weights[layer.name][0], 2))\r\n",
        "      ))\r\n",
        "\r\n",
        "check_is_trainable()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_4 sqr diff: 0.0\n",
            "dense_5 sqr diff: 0.0\n",
            "predictions sqr diff: 13.99891471862793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGC5Dsk0nxuQ"
      },
      "source": [
        "That's ok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sGsJpPrkF31"
      },
      "source": [
        "Try to unfreeze all layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAj5e2_CkcPZ"
      },
      "source": [
        "for layer in model.layers:\r\n",
        "  layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZRs8reAklC-",
        "outputId": "1a378aad-2af5-4359-b6b6-0052d8a8af2a"
      },
      "source": [
        "save_weight()\r\n",
        "train()\r\n",
        "check_is_trainable()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_4 sqr diff: 0.0\n",
            "dense_5 sqr diff: 0.0\n",
            "predictions sqr diff: 0.32455798983573914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vREZVdmn6HX"
      },
      "source": [
        "No success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kcAvfKv1ziY"
      },
      "source": [
        "# Keras API training mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Jm-7CNeu9M"
      },
      "source": [
        "Create model with custom train_step to be sure that trainable vars is got from self.trainable_variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3BKAOb3bP7O"
      },
      "source": [
        "class CustomModel(keras.Model):\r\n",
        "    def train_step(self, data):\r\n",
        "        # Unpack the data. Its structure depends on your model and\r\n",
        "        # on what you pass to `fit()`.\r\n",
        "        x, y = data\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            y_pred = self(x, training=True)  # Forward pass\r\n",
        "            # Compute the loss value\r\n",
        "            # (the loss function is configured in `compile()`)\r\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\r\n",
        "\r\n",
        "        # Compute gradients\r\n",
        "        trainable_vars = self.trainable_variables\r\n",
        "        print(\"Trainable vars\", trainable_vars)\r\n",
        "        gradients = tape.gradient(loss, trainable_vars)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\r\n",
        "        # Update metrics (includes the metric that tracks the loss)\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "        # Return a dict mapping metric names to current value\r\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtVYOTff4ahW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06d242e-e03c-4aff-85a7-1a5414ef155a"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name=\"inputs\")\r\n",
        "x1 = layers.Dense(64, activation=\"relu\", name=\"dense1\")(inputs)\r\n",
        "x2 = layers.Dense(64, activation=\"relu\", name=\"dense2\")(x1)\r\n",
        "outputs = layers.Dense(10, name=\"predictions\")(x2)\r\n",
        "model = CustomModel(inputs=inputs, outputs=outputs)\r\n",
        "[x.trainable for x in model.layers]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, True, True, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHUi_W4yri2o",
        "outputId": "2726f8b0-81fe-452f-983a-29a8a283c88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "[x.name for x in model.trainable_weights]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dense1/kernel:0',\n",
              " 'dense1/bias:0',\n",
              " 'dense2/kernel:0',\n",
              " 'dense2/bias:0',\n",
              " 'predictions/kernel:0',\n",
              " 'predictions/bias:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JMmqomgo5_d"
      },
      "source": [
        "Make callable which can freeze learning\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FDFVeHaqHmE"
      },
      "source": [
        "class FreezingCallback(tf.keras.callbacks.Callback):\r\n",
        "  @staticmethod \r\n",
        "  def copy(weights):\r\n",
        "    res = []\r\n",
        "    for w in weights:\r\n",
        "      res.append(tf.identity(w))\r\n",
        "    return res \r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def have_weights(layer):\r\n",
        "    return hasattr(layer, 'weights') and layer.weights\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def equal(w1, w2):\r\n",
        "    return [(w.name, bool(tf.math.reduce_all(tf.math.equal(w, w_saved)))) \r\n",
        "              for w, w_saved in zip(w1, w2)]\r\n",
        "    \r\n",
        "  def __init__(self, weights_to_freeze, epoch_to_freeze):\r\n",
        "    super().__init__()\r\n",
        "    self.weights_to_freeze = weights_to_freeze\r\n",
        "    self.epoch_to_freeze = epoch_to_freeze\r\n",
        "    self.weights = dict()\r\n",
        "\r\n",
        "  def on_epoch_begin(self, epoch, logs=None):\r\n",
        "    # Keep weights before epoch\r\n",
        "    for layer in self.model.layers:\r\n",
        "      if self.have_weights(layer):\r\n",
        "        self.weights[layer.name] = self.copy(layer.weights)\r\n",
        "        assert all([x[1] for x in \r\n",
        "                   self.equal(layer.weights, self.weights[layer.name])])\r\n",
        "        \r\n",
        "    # Freeze if it's time to freeze\r\n",
        "    if epoch == self.epoch_to_freeze:\r\n",
        "      #gets a reference to the list containing the trainable variables\r\n",
        "      name = tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES\r\n",
        "      trainable_collection = tf.compat.v1.get_collection_ref(name)\r\n",
        "      variables_to_remove = list()\r\n",
        "      print(\"trainable_collection:\", trainable_collection)\r\n",
        "      for vari in trainable_collection:\r\n",
        "          #uses the attribute 'name' of the variable\r\n",
        "        if vari.name in self.weights_to_freeze:\r\n",
        "            variables_to_remove.append(vari)\r\n",
        "      for rem in variables_to_remove:\r\n",
        "        trainable_collection.remove(rem)\r\n",
        "      print(f\"Freeze weights: {variables_to_remove}\")\r\n",
        "  \r\n",
        "  def on_epoch_end(self, epoch, logs=None):\r\n",
        "    print(logs)\r\n",
        "    for layer in self.model.layers:\r\n",
        "      if self.have_weights(layer):\r\n",
        "        equal = self.equal(layer.weights, self.weights[layer.name])\r\n",
        "        print(f\"Layer {layer.name} changed? \"\r\n",
        "              f\"{[(x[0], not x[1]) for x in equal]}\")\r\n",
        "        print(\"sqr diff {}\".format(\r\n",
        "            tf.math.reduce_sum(tf.math.pow(\r\n",
        "                        layer.weights[0] - self.weights[layer.name][0], 2))))\r\n",
        "        # Keep new weights\r\n",
        "        self.weights[layer.name] = self.copy(layer.weights)\r\n",
        "\r\n",
        "\r\n",
        "freezing_callback = FreezingCallback(weights_to_freeze=[\r\n",
        "                                        'dense1/kernel:0',\r\n",
        "                                        'dense1/bias:0',\r\n",
        "                                        'dense2/kernel:0',\r\n",
        "                                        'dense2/bias:0', ],\r\n",
        "                                      epoch_to_freeze=4)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_SUGKadOwoh",
        "outputId": "6d2b2f0f-2616-4b9d-c31e-1fb6264b83a5"
      },
      "source": [
        "# You can change trainable status only before compileing\r\n",
        "for layer in model.layers:\r\n",
        "  layer.trainable = True\r\n",
        "[x.trainable for x in model.layers]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True, True, True, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUX79sJ0qFzK"
      },
      "source": [
        "compile_kwargs = {\r\n",
        "    'optimizer': keras.optimizers.SGD(learning_rate=1e-3), \r\n",
        "    'loss': keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    'metrics': [keras.metrics.SparseCategoricalAccuracy()],\r\n",
        "}\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    **compile_kwargs\r\n",
        ")\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "oeDKvkzKyE0K",
        "outputId": "f1bcb86c-a1ac-4da6-f910-4ed7e21f724f"
      },
      "source": [
        "# Setup trainable param\r\n",
        "#for layer in model.layers:\r\n",
        "#  layer.trainable = False\r\n",
        "#model.trainable = False\r\n",
        "\r\n",
        "model.fit(\r\n",
        "    x_train,\r\n",
        "    y_train,\r\n",
        "    batch_size=32,\r\n",
        "    epochs=10,\r\n",
        "    callbacks=[freezing_callback]\r\n",
        ")\r\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-3c0494c92298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfreezing_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-64b24b3e614a>\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         assert all([x[1] for x in \n\u001b[0;32m---> 31\u001b[0;31m                    self.equal(layer.weights, self.weights[layer.name])])\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Freeze if it's time to freeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    <ipython-input-59-64b24b3e614a>:17 equal  *\n        for w, w_saved in zip(w1, w2)]\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:885 __bool__  **\n        self._disallow_bool_casting()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:489 _disallow_bool_casting\n        \"using a `tf.Tensor` as a Python `bool`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:476 _disallow_when_autograph_enabled\n        \" indicate you are trying to use an unsupported feature.\".format(task))\n\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36wou52MVU3t"
      },
      "source": [
        "# TF1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCP_2insVaz8",
        "outputId": "47389907-dbd5-4c27-b924-486a387bc34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov0y1oFAVkDw"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name=\"inputs\")\r\n",
        "x1 = layers.Dense(64, activation=\"relu\", name=\"dense1\")(inputs)\r\n",
        "x2 = layers.Dense(64, activation=\"relu\", name=\"dense2\")(x1)\r\n",
        "outputs = layers.Dense(10, name=\"predictions\")(x2)\r\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzAzlDfkV-Jt"
      },
      "source": [
        "class TF1FreezingCallback(tf.keras.callbacks.Callback):\r\n",
        "  @staticmethod \r\n",
        "  def copy(weights):\r\n",
        "    res = []\r\n",
        "    for w in weights:\r\n",
        "      res.append(tf.identity(w))\r\n",
        "    return res \r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def have_weights(layer):\r\n",
        "    return hasattr(layer, 'weights') and layer.weights\r\n",
        "\r\n",
        " # @staticmethod\r\n",
        " # def equal(w1, w2):\r\n",
        "#    return [(w.name, bool(tf.math.reduce_all(tf.math.equal(w, w_saved)))) \r\n",
        " #             for w, w_saved in zip(w1, w2)]\r\n",
        "    \r\n",
        "  def __init__(self, weights_to_freeze, epoch_to_freeze):\r\n",
        "    super().__init__()\r\n",
        "    self.weights_to_freeze = weights_to_freeze\r\n",
        "    self.epoch_to_freeze = epoch_to_freeze\r\n",
        "    self.weights = dict()\r\n",
        "\r\n",
        "  def on_epoch_begin(self, epoch, logs=None):\r\n",
        "    # Keep weights before epoch\r\n",
        "    for layer in self.model.layers:\r\n",
        "      if self.have_weights(layer):\r\n",
        "        self.weights[layer.name] = self.copy(layer.weights)\r\n",
        "                \r\n",
        "    # Freeze if it's time to freeze\r\n",
        "    if epoch == self.epoch_to_freeze:\r\n",
        "      #gets a reference to the list containing the trainable variables\r\n",
        "      name = tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES\r\n",
        "      trainable_collection = tf.compat.v1.get_collection_ref(name)\r\n",
        "      variables_to_remove = list()\r\n",
        "      print(\"trainable_collection:\", trainable_collection)\r\n",
        "      for vari in trainable_collection:\r\n",
        "          #uses the attribute 'name' of the variable\r\n",
        "        if True:#vari.name in self.weights_to_freeze:\r\n",
        "            variables_to_remove.append(vari)\r\n",
        "      for rem in variables_to_remove:\r\n",
        "        trainable_collection.remove(rem)\r\n",
        "      print(f\"Freeze weights: {variables_to_remove}\")\r\n",
        "  \r\n",
        "  def on_epoch_end(self, epoch, logs=None):\r\n",
        "    print(logs)\r\n",
        "    for layer in self.model.layers:\r\n",
        "      if self.have_weights(layer):\r\n",
        "        #equal = self.equal(layer.weights, self.weights[layer.name])\r\n",
        "        #print(f\"Layer {layer.name} changed? \"\r\n",
        "        #      f\"{[(x[0], not x[1]) for x in equal]}\")\r\n",
        "        print(\"sqr diff {}\".format(\r\n",
        "            tf.math.reduce_sum(tf.math.pow(\r\n",
        "                        layer.weights[0] - self.weights[layer.name][0], 2)\r\n",
        "                            )))\r\n",
        "        # Keep new weights\r\n",
        "        self.weights[layer.name] = self.copy(layer.weights)\r\n",
        "\r\n",
        "\r\n",
        "freezing_callback = TF1FreezingCallback(weights_to_freeze=[\r\n",
        "                                        'dense1/kernel:0',\r\n",
        "                                        'dense1/bias:0',\r\n",
        "                                        'dense2/kernel:0',\r\n",
        "                                        'dense2/bias:0', ],\r\n",
        "                                      epoch_to_freeze=4)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32QwOsZsTHI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7fa045-1add-4d7a-b1b8-98d666c09f51"
      },
      "source": [
        "c_name = tf.compat.v1.get_default_graph().collections\r\n",
        "graph = tf.compat.v1.get_default_graph()\r\n",
        "for name in c_name:\r\n",
        "  print(f'{name} - {graph.get_collection_ref(name)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "variables - []\n",
            "local_variables - []\n",
            "trainable_variables - []\n",
            "('__variable_store',) - []\n",
            "('__varscope',) - [<tensorflow.python.ops.variable_scope._VariableScopeStore object at 0x7f1d3de32ee8>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0F_9uoUU04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fdac56-9f0b-4602-b8fc-4538da37b56d"
      },
      "source": [
        "tf.compat.v1.get_default_graph()._collections['trainable_variables']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPGzWwpDWuSy",
        "outputId": "a4308659-2977-4ab0-8fc0-fcc5a3549f1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#s = tf.Session()\r\n",
        "#with s.as_default():\r\n",
        "model.fit(\r\n",
        "      x_train,\r\n",
        "      y_train,\r\n",
        "      batch_size=32,\r\n",
        "      epochs=10,\r\n",
        "      callbacks=[freezing_callback]\r\n",
        "  )\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/10\n",
            "49152/50000 [============================>.] - ETA: 0s - loss: 1.6243 - sparse_categorical_accuracy: 0.6637{'loss': 1.61086017162323, 'sparse_categorical_accuracy': 0.66588}\n",
            "sqr diff Tensor(\"Sum:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_1:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_2:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 40us/sample - loss: 1.6109 - sparse_categorical_accuracy: 0.6659\n",
            "Epoch 2/10\n",
            "49184/50000 [============================>.] - ETA: 0s - loss: 0.6090 - sparse_categorical_accuracy: 0.8356{'loss': 0.6081333211946487, 'sparse_categorical_accuracy': 0.8361}\n",
            "sqr diff Tensor(\"Sum_3:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_4:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_5:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.6081 - sparse_categorical_accuracy: 0.8361\n",
            "Epoch 3/10\n",
            "49888/50000 [============================>.] - ETA: 0s - loss: 0.4720 - sparse_categorical_accuracy: 0.8714{'loss': 0.47158344211041925, 'sparse_categorical_accuracy': 0.87152}\n",
            "sqr diff Tensor(\"Sum_6:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_7:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_8:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.4716 - sparse_categorical_accuracy: 0.8715\n",
            "Epoch 4/10\n",
            "48992/50000 [============================>.] - ETA: 0s - loss: 0.4045 - sparse_categorical_accuracy: 0.8879{'loss': 0.4039499175012112, 'sparse_categorical_accuracy': 0.88812}\n",
            "sqr diff Tensor(\"Sum_9:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_10:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_11:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 39us/sample - loss: 0.4039 - sparse_categorical_accuracy: 0.8881\n",
            "trainable_collection: [<tf.Variable 'dense1/kernel:0' shape=(784, 64) dtype=float32>, <tf.Variable 'dense1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'dense2/kernel:0' shape=(64, 64) dtype=float32>, <tf.Variable 'dense2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(64, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]\n",
            "Freeze weights: [<tf.Variable 'dense1/kernel:0' shape=(784, 64) dtype=float32>, <tf.Variable 'dense1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'dense2/kernel:0' shape=(64, 64) dtype=float32>, <tf.Variable 'dense2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'predictions/kernel:0' shape=(64, 10) dtype=float32>, <tf.Variable 'predictions/bias:0' shape=(10,) dtype=float32>]\n",
            "Epoch 5/10\n",
            "49568/50000 [============================>.] - ETA: 0s - loss: 0.3632 - sparse_categorical_accuracy: 0.8972{'loss': 0.3633847408860922, 'sparse_categorical_accuracy': 0.89712}\n",
            "sqr diff Tensor(\"Sum_12:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_13:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_14:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.3634 - sparse_categorical_accuracy: 0.8971\n",
            "Epoch 6/10\n",
            "49248/50000 [============================>.] - ETA: 0s - loss: 0.3337 - sparse_categorical_accuracy: 0.9049{'loss': 0.33323065760850906, 'sparse_categorical_accuracy': 0.90496}\n",
            "sqr diff Tensor(\"Sum_15:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_16:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_17:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.3332 - sparse_categorical_accuracy: 0.9050\n",
            "Epoch 7/10\n",
            "49312/50000 [============================>.] - ETA: 0s - loss: 0.3110 - sparse_categorical_accuracy: 0.9111{'loss': 0.31115302505552767, 'sparse_categorical_accuracy': 0.9109}\n",
            "sqr diff Tensor(\"Sum_18:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_19:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_20:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.3112 - sparse_categorical_accuracy: 0.9109\n",
            "Epoch 8/10\n",
            "48960/50000 [============================>.] - ETA: 0s - loss: 0.2902 - sparse_categorical_accuracy: 0.9157{'loss': 0.2913324162876606, 'sparse_categorical_accuracy': 0.91556}\n",
            "sqr diff Tensor(\"Sum_21:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_22:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_23:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 39us/sample - loss: 0.2913 - sparse_categorical_accuracy: 0.9156\n",
            "Epoch 9/10\n",
            "49216/50000 [============================>.] - ETA: 0s - loss: 0.2778 - sparse_categorical_accuracy: 0.9201{'loss': 0.27725768759042024, 'sparse_categorical_accuracy': 0.92024}\n",
            "sqr diff Tensor(\"Sum_24:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_25:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_26:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 39us/sample - loss: 0.2773 - sparse_categorical_accuracy: 0.9202\n",
            "Epoch 10/10\n",
            "48800/50000 [============================>.] - ETA: 0s - loss: 0.2634 - sparse_categorical_accuracy: 0.9233{'loss': 0.26274646789468825, 'sparse_categorical_accuracy': 0.92352}\n",
            "sqr diff Tensor(\"Sum_27:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_28:0\", shape=(), dtype=float32)\n",
            "sqr diff Tensor(\"Sum_29:0\", shape=(), dtype=float32)\n",
            "50000/50000 [==============================] - 2s 39us/sample - loss: 0.2627 - sparse_categorical_accuracy: 0.9235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5837a66390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}